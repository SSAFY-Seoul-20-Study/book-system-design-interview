# 4장 처리율 제한 장치의 설계


**[ 처리율 제한 장치 ]** : 클라이언트 또는 서비스가 보내는 트래픽 처리율을 제어하기 위한 장치

**[ 사례 ]**

- 트위터는 3시간 동안 300개의 트윗만 올릴 수 있도록 제한
- 구글 독스 API는 사용자당 분당 300회의 read 요청만 허용

**[ 처리율 제한장치를 두면 좋은 점 ]**

- DoS 공격에 의한 자원 고갈을 방지
- 서버를 많이 두지 않고, 우선순위가 높은 API에 더 많은 자원을 할당하고, 비용을 절감할 수 있음
- 봇, 잘못된 이용 패턴으로 유발된 트래픽을 걸러내어 서버 과부하 방지


## [ 1단계 ] 문제 이해 및 설계 범위 확정

### 어떤 처리율 제한 장치를 구현해야 하는가?

```
Q. 어떤 종류의 처리율 제한 장치를 설계해야 하나요?
A. 서버 측 제한 장치
Q. 어떤 기준에 따라 API 호출을 제어해야 하는지
A. 다양한 형태의 제어 규칙을 정의할 수 있는 유연한 시스템
Q. 시스템 규모는 어느 정도인가요?
A. 대규모 요청을 처리할 수 있어야 한다.
Q. 분산 환경에서 동작해야 하는가?
A. YES
Q. 독립된 서비스인가요, 애플리케이션 코드에 포함되나요?
A. 알아서
Q. 사용자의 요청이 처리율 제한 장치에 의해 걸러진 경우, 사용자에게 알려야 하는가?
A. YES
```

### **시스템 요구사항**

- 설정된 처리율을 초과하는 요청을 정확하게 제한한다.
- 낮은 응답시간: HTTP 응답 시간에 나쁜 영향을 주어서는 곤란한다.
- 가능한 적은 메모리를 사용한다.
- 분산형 처리율 제한: 하나의 처리율 제한장치를 여러 서버나 프로세스에서 공유
- 예외 처리: 요청이 제한되었을 때는 사용자에게 분명히 보여주어야 함
- 높은 결함 감내성: 제한 장치에 장애가 생기더라도 전체 시스템에 영향을 주어서는 안됨

## **[ 2단계 ] 문제 이해 및 설계 범위 확정**

### **처리율 제한 장치는 어디에 둘 것인가?**

- **클라이언트**: 클라이언트 요청은 쉽게 위변조가 가능하기 때문에 처리율 제한을 안정적으로 걸 수 없고, 모든 클라이언트의 구현을 통제하기 어려움
- **서버**: 애플리케이션 코드에 처리율 제한 장치를 포함하여 서버 측에서 통제
    - 장점: 자유롭게 처리율 제한 알고리즘을 선택할 수 있음
    - 단점: 처리율 제한 장치 구현 인력이 추가 필요, 상용 중인 PGL이 서버 측 구현을 지원할 만큼 효율이 높은지 검토가 필요
    ![image](https://github.com/SSAFY-Seoul-20-Study/book-system-design-interview/assets/77006790/33e671ee-bb66-4b9d-933f-52d0954a4125)

    
- **미들웨어**: 처리율 제한 미들웨어를 만들어 미들웨어에서 API 서버로 가는 요청을 통제
    - 장점: API Gateway가 지원해주기에 비교적 구현이 쉬움
    - 단점: 미들웨어를 커스텀하기 어려울 수 있음, 미들웨어에 문제가 생기면 전체 처리율 제한 처리에도 문제가 생김
    ![image](https://github.com/SSAFY-Seoul-20-Study/book-system-design-interview/assets/77006790/6a5d28fb-d550-407c-89ab-032d115cb65a)

    - API 게이트 웨이: 처리율 제한, SSL 종단, 사용자 인증, IP 허용 목록 관리 등을 지원하는 완전 위탁 관리형 서비스로, 클라우드 업체가 유지 보수를 담당하는 서비스   
      => **처리율 제한을 지원하는 미들웨어**

📖 **지침**
1. 프로그래밍 언어, 캐시 서비스 등 현재 사용하고 있는 기술 스택을 점검 => 서버 측 구현을 지원하기 충분할 정도로 효율이 높은가
2. 사업 필요에 맞는 처리율 제한 알고리즘 찾기
3. 마이크로 서비스에 기반하고, API 게이트웨이를 이미 설계에 포함시킨 경우, 처리율 제한 기능 또한 게이트웨이에 포함시켜야 할 수 있음
4. 처리율 제한 장치를 구현하기에 충분한 인력이 없다면 API 게이트웨이를 쓰는 것이 바람직

### **처리율 제한 알고리즘**

> **얼마나 많은 요청이 접수되었는지를 추적할 수 있는 카운터를 추적 대상별로 두고, 이 카운터의 값이 어떤 한도를 넘어 도착한 요청은 거부**
> 
- **토큰 버킷 알고리즘**: 폭 넓게 이용되고, 인터넷 기업들이 보편적으로 사용
    - 토큰 버킷: 지정된 용량을 갖는 컨테이너
    - 동작 원리
        1. 토큰 버킷에 사전 설정된 양의 토큰이 주기적으로 채워짐
            - 토큰 공급기는 이 버킷에 매초 토큰을 추가
            - 버킷이 가득 차면 추가로 공급된 토큰은 버려짐(overflow)
        2. 각 요청은 처리될 때마다 하나의 토큰을 사용
            - 충분한 토큰이 있는 경우, 버킷에서 토큰 하나를 꺼낸 후 요청을 시스템에 전달
            - 충분한 토큰이 없는 경우, 해당 요청은 버려짐(dropped)
        ![image](https://github.com/SSAFY-Seoul-20-Study/book-system-design-interview/assets/77006790/b23140f5-652c-419f-8f4e-eb25ad68e17f)

    - 사례
        1. 통상적으로, API 엔드포인트 마다 별도의 버킷을 둔다. 
            - 사용자마다 하루에 한 번만 포스팅, 친구는 150명까지 추가, 좋아요 버튼은 5번까지 누를 수 있음 => 사용자마다 3개의 버킷이 필요
        2. IP 주소별로 처리율 제한을 적용한다면 IP 주소마다 버킷을 하나씩 할당
        3. 시스템의 처리율을 초당 10,000개 요청으로 제한하고 싶다면 모든 요청이 하나의 버킷을 공유하도록 해야 함   
       **=> 아마존, 스트라이프 같은 일반적 기업이 API 통제하기 위해 사용**
    - 장점
        1. 구현이 쉽다.
        2. 메모리 사용 측면에서 효율적
        3. 버킷에 토큰이 남아있기만 하면 요청은 시스템에 전달되므로, 짧은 시간에 집중되는 트래픽 처리 가능
    - 단점
        1. 두 인자(버킷 크기, 토큰 공급률)을 적절히 튜닝하기 어려움
            - 버킷 크기: 버킷에 담을 수 있는 토큰의 최대 개수
            - 토큰 공급률: 초당 몇개의 토큰이 버킷에 공급되는가
  - **누출 버킷 알고리즘**: 토큰 버킷 알고리즘과 달리 요청처리율이 고정되어 있으며, FIFO 큐로 구현
    - 동작 원리
        1. 요청이 도착하면 큐에 빈자리가 있는 지 확인 후, 큐에 요청을 추가
        2. 큐가 가득차있는 경우, 새 요청은 버림
        3. 지정된 시간마다 큐에서 요청을 꺼내어 처리
        ![image](https://github.com/SSAFY-Seoul-20-Study/book-system-design-interview/assets/77006790/a36eadce-d6d1-4dd6-b419-2de620ee9eb2)

    - 장점
        1. 큐의 크기가 제한되어 있어 메모리 사용량 측면에서 효율적
        2. 고정된 처리율을 갖고 있기 때문에 안정적 출력이 필요한 경우 적합
        
        **=> 전자상거래 기업인 쇼피파이가 처리율 제한을 구현**
        
    - 단점
        1. 단시간에 많은 트래픽이 몰리는 경우, 큐에 요청이 쌓여 최신 요청들이 버려질 수 있음
        2. 두 인자(버킷 크기, 처리율)을 적절히 튜닝하기 어려움 
            - 버킷 크기: 큐 사이즈와 같은 값
            - 처리율: 지정된 시간당 몇개의 항목을 처리할지 지정하는 값
- **고정 윈도 카운터**
    - 동작 원리
        1. 타임라인을 고정된 간격의 윈도로 나누고, 각 윈도마다 카운터를 붙임
        2. 요청이 접수될 때마다 카운터의 값이 1씩 증가
        3. 카운터의 값이 사전에 설정된 임계치에 도달하면 새로운 요청은 새 윈도가 열릴 때까지 버려짐
        
        ![image](https://github.com/SSAFY-Seoul-20-Study/book-system-design-interview/assets/77006790/a8e13ed8-5982-422e-93d1-b17e8a99d7ff)

    - 장점
        1. 메모리 효율이 좋음
        2. 이해하기 쉬움
        3. 특정한 트래픽 패턴을 처리하기에 적합
    - 단점
        1. 윈도 경계 부근에서 일시적으로 많은 트래픽이 몰려드는 경우, 기대했던 시스템의 처리 한도보다 많은 양의 요청을 처리하게 됨
        ![image](https://github.com/SSAFY-Seoul-20-Study/book-system-design-interview/assets/77006790/78c5b326-cbc3-4edb-a402-0fc056f885aa)

- **이동 윈도 로그**
    - 동작 원리
        1. 요청의 타임 스탬프를 추척
            - 타임 스탬프 데이터는 보통 Redis의 정렬 집합 같은 캐시에 보관
        2. 새 요청이 오면 만료된 타임스탬프 제거
        3. 새 요청의 타임스탬프를 로그에 추가
        4. 로그의 크기가 허용치보다 같거나 작으면 요청을 시스템에 전달하고, 그렇지 않으면 처리 거부
        ![image](https://github.com/SSAFY-Seoul-20-Study/book-system-design-interview/assets/77006790/eb923802-4b8e-41c9-b9b5-61b41635833a)

       
    - 장점
        1. 어느 순간의 윈도를 보더라도, 허용되는 요청의 개수는 시스템의 처리율 한도를 넘지 않음
    - 단점
        1. 거부된 요청의 타임스탬프도 보관하여 다량의 메모리를 사용함
- **이동 윈도 카운터**: 고정 윈도 카운터 알고리즘과 이동 윈도 로깅 알고리즘을 결합
    - 접근 방법
        
        ![image](https://github.com/SSAFY-Seoul-20-Study/book-system-design-interview/assets/77006790/c2d8a9c0-c314-48c5-a050-d087af495acc)
        
        1. 현재 1분의 30% 시점에 도착한 신규 요청이 들어왔을 때, 현재 윈도에 들어있는 요청의 개수
            1. 현재 1분간의 요청 수 + 직전 1분간의 요청 수 * 이동 윈도와 직전 1분이 겹치는 비율 
            
            ex) 3 + 5 * 70% = 6.5개 => 6개
            
        2. 1분의 30% 시점에 들어온 신규 요청은 시스템에 전달되지만, 그 직후 한도에 도달하여 요청을 받지 못함
    - 장점
        1. 이전 시간대의 평균 처리율에 따라 현재 윈도의 상태를 계산하므로 짧은 시간에 몰리는 트래픽에 잘 대응
        2. 메모리 효율이 좋음
    - 단점
        1. 직전 시간대에 도착한 요청이 균등하게 본포되어 있다고 가정해 다소 느슨 -> 그러나, 클라우드플레어가 실시했던 실험에 따르면 40억 개의 요청 가운데 잘못 처리한 요청은 0.003%
        

### **계략적인 아키텍처**

- **카운터는 메모리 상에서 동작하는 캐시에 보관하는 것이 바람직**
    1. 디스크 접근 때문에 속도가 느린 DB에 비해 빠름 
    2. 시간에 기반한 만료정책을 지원
- Redis: 모든 데이터를 메모리에 저장하고 조회하는 인메모리 데이터 베이스
    - 처리율 제한 장치를 구현할 때 자주 사용되는 메모리 기반 저장장치
    - INCR와 EXPIRE의 두 가지 명령어를 지원
        - INCR: 메모리에 저장된 카운터의 값을 1만큼 증가
        - EXPIRE: 카운터에 타임아웃 값을 설정하여 시간이 지나면 자동으로 삭제
- 처리율 제한 장치의 개략적 구조

![image](https://github.com/SSAFY-Seoul-20-Study/book-system-design-interview/assets/77006790/f08328aa-9261-439f-bb78-511d768cd21d)

1. 클라이언트가 처리율 제한 미들웨어에 요청을 보냄
2. 처리율 제한 미들웨어는 레디스의 지정 버켓이서 카운터를 가져와서 한도에 도달했는지 아닌지 검사
    - 한도에 도달하면 요청은 거부
    - 한도에 도달하지 않았다면 요청은 API 서버로 전달, 미들웨어는 카운터의 값을 증가시킨 후 다시 레디스에 저장
