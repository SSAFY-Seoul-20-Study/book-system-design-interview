## 장애처리

> 대다수 대규모 시스템에서 장애는 아주 흔하게 벌어지는 사건이므로, 장애를 어떻게 처리하냐는 매우 중요한 문제이다.
> 

### 장애 감지

- 보통 두 대이상의 서버가 똑같이 서버 A의 장애를 보고해야 해당 서버에 실제로 장애가 발생했다고 간주
- 모든 서버에 멀티캐스팅 채널을 구축하는 것은 가장 쉬운 방법이지만, 서버가 많을 때는 비효율적
    
    ⇒ 가십 프로토콜 같은 분산형 장애 감지 솔루션
    
- 가십 프로토콜
  ![image](https://github.com/SSAFY-Seoul-20-Study/book-system-design-interview/assets/77006790/582f63e2-edc5-4b20-a510-774082ed1783)
    1. 각 노드는 멤버십 목록을 유지한다.
        1. 멤버십 목록 : 각 멤버 ID와 그 heartbeat counter 쌍의 목록
        
        ** heartbeat : 분산 시스템이 노드들끼리 각자의 상태를 공유하는 것
        
    2. 각 노드는 주기적으로 자신의 heartbeat counter를 증가시킨다.
    3. 각 노드는 무작위로 선정된 노드들에게 주기적으로 자기 heartbeat counter 목록을 보낸다.
    4. heartbeat counter 목록을 받은 노드는 멤버십 목록을 최신 값으로 갱신한다.
    5. 어떤 멤버의 heartbeat counter 값이 지정된 시간동안 갱신되지 않으면 해당 멤버는 장애(offline) 상태 인 것으로 간주한다.

** 가십 프로토콜 외

- Centralized : 한 노드가 모든 노드를 체크 ⇒ 확장성이 낮고, 체크하는 노드가 실패인 경우 확인할 수 없음
- Ring: 각 노드들은 양 옆의 노드만 체크 ⇒ 연속된 3개의 노드가 한번에 Fail되면 확인할 수 없고, 양 옆의 노드가 회복될 때 까지 아주 높은 latency가 발생할 수 있음
- All-to-All: 모든 노드들이 체크 ⇒ 서로를 fail로 체크할 수 있음

:point_right: [참조 사이트](https://medium.com/@heonjang.lee96/distributed-system%EC%9D%80-failure%EC%9D%84-%EC%96%B4%EB%96%BB%EA%B2%8C-%ED%83%90%EC%A7%80%ED%95%A0%EA%B9%8C-heartbeat-2-8c553577c943#:~:text=%EA%B7%B8%EB%A0%87%EB%8B%A4%EB%A9%B4%20%EB%8B%A4%EC%9D%8C%20heartbeat%20counter%EC%97%90%EC%84%9C%202%EB%B2%88%EB%85%B8%EB%93%9C%EA%B0%80%20%EB%8B%A4%EC%9D%8C%EA%B3%BC%20%EA%B0%99%EC%9D%B4,3%EB%B2%88%EB%85%B8%EB%93%9C%EB%A5%BC%20%EB%8B%A4%EC%8B%9C%20Membership%EB%A6%AC%EC%8A%A4%ED%8A%B8%EC%97%90%20%EB%B3%B5%EA%B7%80%EC%8B%9C%ED%82%A4%EB%8A%94%20%EC%98%A4%EB%A5%98%EA%B0%80%20%EB%B0%9C%EC%83%9D%ED%95%98%EA%B2%8C%20%EB%90%9C%EB%8B%A4)

### 일시적 장애 처리

- 장애를 감지한 시스템은 **가용성**을 보장하기 위해 필요한 조치를 해야 함

- Quorum(쿼럼) : 읽기의 최소 성공 수를 R, 쓰기의 최소 성공 수를 W라는 변수를 사용해 시스템에서 읽기와 쓰기의 실패 여부를 확인하는 방법
    - 노드 그룹 간에 네트워크 단절 등으로 인해 공유하고 있던 데이터가 오염되며 데이터 충돌이 발생할 수 있다. ⇒ 이를 해결하기 위한 방법 중 하나가 quorum
    
  :point_right: [분산환경에서 Quorum(정족수)은 왜 필요할까 / Quorum이란 무엇인가](https://2kindsofcs.tistory.com/79)
    
- 엄격한 정족수(strict quorum) 접근법
    - 읽기와 쓰기 연산 금지
    
    ⇒ **데이터 일관성 유지**
    

- 느슨한 정족수(sloppy quorum) 접근법
    - 일부 장애가 발생한 상황에서 여전히 쓰기 연산을 할 수 있게 하는 것
    - **hinted handoff**

    1. 쓰기 연산을 수행할 W개의 건강한 서버와 읽기 연산을 수행할 R개의 건강한 서버를 해시 링에서 고름 ( 장애 상태인 서버는 무시)
    2. 장애 서버로 가는 요청을 다른 서버가 잠시 맡아 처리하고, 장애서버가 복구되면 변경사항을 일관 반영 ⇒ **데이터 일관성** 보존
    3. 임시로 쓰기연산을 처리할 서버에는 hint를 남김   
     ⇒ **가용성을 높임**

    ![image](https://github.com/SSAFY-Seoul-20-Study/book-system-design-interview/assets/77006790/08d7c875-0497-40a4-9a2f-5125272bc4fa)
   

  
### 영구 장애 처리

- 반-엔트로피 (anti-entropy) 프로토콜
    - 사본들을 비교하여 최신 버전으로 갱신하는 것
    - 사본 간의 **데이터 일관성**을 보장하기 위해 사용되는 메커니즘
    - 유형
        - 읽기 복구: 읽기 요청시 시스템은 여러 복제본에서 읽고, 불일치가 감지되면 이전 버전이 최신 버전으로 업데이트
        - 활성 안티 엔트로피: 읽기/쓰기 작업이 없는 경우에도 주기적인 동기화
    - 사례
        - 분산 데이터베이스: Cassandra 및 Riak와 같은 데이터 베이스에서 일관성 유지를 보장
        - 버전 제어 시스템: Git 과 같은 시스템이 분기를 병합하고 충돌을 해결할 때
        - 파일 동기화: Dropbox 또는 Google Drive 같은 서비스는 파일 버전이 여러 장치에서 일관되도록 유지
    - 사본 간의 일관성이 망가진 상태를 탐지하고 전송 데이터 양을 줄여야함 ⇒ 머클 트리
    
    :point_right:[참조 사이트](https://www.linkedin.com/pulse/anti-entropy-protocols-yeshwanth-n-2c#:~:text=Anti%2Dentropy%20protocols%20are%20mechanisms%20used%20in%20distributed%20systems%20to%20ensure%20data%20consistency%20across%20replicas)
- **머클 트리(해시 트리)**
    - 반엔트로피에 사용되는 일반적인 데이터 구조
    - 각 노드에 그 자식 노드들에 보관된 값의 해시, 또는 자식 노드들의 레이블로부터 계산된 해시값을 레이블로 붙여두는 트리
    - 모든 자식 노드들이 암호학적 해시로 이루어진 데이터 블록을 갖는 트리 형태의 자료 구조
    - 블록 단위로 빠르게 데이터를 검증하고, 이상 유무를 확인할 수 있어 많이 사용
    
    1. 키 공간을 버킷으로 나눈다.
    2. 버킷에 포함된 각각의 키에 균등 분포 해시 함수를 적용하여 해시 값을 계산한다.
    3. 버킷 별로 해시 값을 계산한 후, 해당 해시 값을 레이블로 갖는 노드를 만든다.
    4. 자식 노드의 레이블로부터 새로운 해시 값을 계산하여, 이진 트리를 상향식으로 구성해 나간다.
    
    - 두 머클 트리 비교
        - 루트 노드의 해시값을 비교
        - 값이 동일하면 두 서버는 같은 데이터
        - 값이 다른 경우 왼쪽 자식 노드의 해시값을 비교 후 오른쪽 자식 노드 해시값 비교
        
        ⇒ 다른 데이터를 갖는 버킷들만 동기화
        

### 데이터 센터 장애 처리

- 데이터 센터 장애는 정전, 네트워크 장애, 자연재해 등 다양한 이유로 발생
- 데이터를 여러 데이터 센터에 다중화 하는 것이 중요

⇒ 현 데이터 센터가 망가져도, 다른 데이터 센터에 보관된 데이터를 이용할 수 있음

## 시스템 아키텍처 다이어그램
![image](https://github.com/SSAFY-Seoul-20-Study/book-system-design-interview/assets/77006790/4db2b261-0d2e-4315-a4d7-1128efe9381b)

- 기능
    - 클라이언트는 키-값 저장소가 제공하는 두 가지 단순한 API, 즉 get(key) 및 put(key, value)와 통신한다.
    - 중재자는 클라이언트에게 키-값 저장소에 대한 Proxy역할을 하는 노드다
    - 노드는 안정 해시의 해시링 위에 분포한다.
    - 노드를 자동으로 추가 또는 삭제할 수 있도록, 시스템은 완전히 분산된다.
    - 데이터는 여러 노드에 다중화된다.
    - 모든 노드가 같은 책임을 지므로 SPOF(단일 장애 지점)는 존재하지 않는다.

## 쓰기 경로
![image](https://github.com/SSAFY-Seoul-20-Study/book-system-design-interview/assets/77006790/fbc7d806-5d24-4dcf-9410-a1318623de9a)

- 쓰기 요청이 특정 노드에 전달되는 경우 - 카산드라 사례
1. 쓰기 요청이 커밋 로그 파일에 기록된다
2. 데이터가 메모리 캐시에 기록된다.
3. 메모리 캐시가 가득차거나 사전에 정의된 어떤 임계치에 도달하면 데이터는 디스크에 있는 SSTable에 기록

** 카산드라 : 페이스북이 개발한 대용량 처리가 가능한 비관계형 분산 DBMS, **가용성**을 위주로 확장성을 유지한 채 데이터를 핸들링

** SSTable :  Sorted-String Table의 약어로, <키, 값> 의 순서쌍을 정렬된 리스트 형태로 관리하는 테이블, Casssandra에서 데이터를 디스크에 저장하는데 사용되는 기본 저장 단위

## 읽기 경로
![image](https://github.com/SSAFY-Seoul-20-Study/book-system-design-interview/assets/77006790/5f6b12fb-8271-4d7f-bdd9-1faf960309c1)

- 읽기 요청을 받은 노드의 동작
1. 데이터가 메모리 캐시에 있는지 확인
    1. 있는 경우, 해당 데이터를 클라이언트에게 반환
2. 없는 경우, 디스크에서 가져와야 하므로, 블룸 필터 검사
3. 블룸 필터를 통해 어떤 SSTable에 키가 보관되어 있는지 알아냄
4. SSTable에서 데이터를 가져옴
5. 해당 데이터를 클라이언트에게 반환

** 블룸 필터(Bloom Filter) : 데이터 블록에 특정 key의 데이터가 존재하는지 확인할 수 있는 확률형 자료구조

1. N개의 Bit로 이루어진 Bitmap을 만듦
2. K개의 Hash 함수를 이용하여 K개의 숫자를 가져옴
3. Bitmap 안에 각 K개의 숫자들 위치를 true로 만듦

⇒ 하나라도 False가 있다면 존재하지 않는다고 확신

⇒ 없다고 하면 확실히 없지만, 있다고 하면 있을 수도 없을 수도 있다.

## 요약

| 목표/문제 | 기술 |
| --- | --- |
| 대규모 데이터 저장 | 안정 해시를 사용해 서버들에 부하 분산 |
| 읽기 연산에 대한 높은 가용성 보장 | 데이터를 여러 데이터 센터에 다중화 |
| 쓰기 연산에 대한 높은 가용성 보장 | 버저닝 및 벡터시계를 사용한 충돌 해소 |
| 대규모 파티션 | 안정 해시 |
| 점진적 규모 확장성 | 안정 해시 |
| 다양성 | 안정 해시 |
| 조절 가능한 데이터 일관성 | 정족수 합의 |
| 일시적 장애 처리 | 느슨한 정족수 프로토콜과 단서 후 임시 위탁 |
| 영구적 장애 처리 | 머클 트리 |
| 데이터 센터 장애 대응 | 여러 데이터 센터에 걸친 데이터 다중화 |
